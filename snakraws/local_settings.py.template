"""
Django settings for SnakrAWS project.

Generated by 'django-admin startproject' using Django 2.1.5.

For more information on this file, see
https://docs.djangoproject.com/en/2.1/topics/settings/

For the full list of settings and their values, see
https://docs.djangoproject.com/en/2.1/ref/settings/
"""
import string


def _(value):
    return value

# don't run with debug turned on in production!
DEBUG = True
TEST_LOW_CAPTCHA_SCORE = False
SITE_MODE = 'dev'
DATABASE_MODE = 'dev'
SITE_ID = 1
APP_NAME = "snakraws"
VERBOSE_NAME = "SnakrAWS"
PUBLIC_NAME = VERBOSE_NAME
PAGE_TITLE = "Snakr All-Vegetable URL Shortening"
AWS_ELASTIC_IP = "your.aws.elastic.ip"

# Generated on the Google site
ENABLE_ANALYTICS = True
ENABLE_GOOGLE_ANALYTICS = True if SITE_MODE == 'prod' else False
GOOGLE_ANALYTICS_WEB_PROPERTY_ID = "your GA wpid"
# Generated on the FB site, fopr sharing to FB
FACEBOOK_APP_ID="your FB app id"
# Generated on the LinkedIn site, for sharing to LI
LINKEDIN_CLIENT_ID = "your LI client ID"
LINKEDIN_CLIENT_SECRET = "your LI client secret"

ENABLE_LOGGING = True
VERBOSE_LOGGING = True
SSL_ENABLED = False
ENABLE_BOT_DETECTION = False

if SITE_MODE == 'dev':
    SHORTURL_HOST = "localhost:8000"
else:
    SHORTURL_HOST = "your.url.here"

RECAPTCHA_PRIVATE_KEY = 'your Google reCAPTCHA v3 private key here'
RECAPTCHA_PUBLIC_KEY = 'your Google reCAPTCHA v3 public key here'
RECAPTCHA_DEFAULT_ACTION = 'generic'
RECAPTCHA_SCORE_THRESHOLD = 0.5

ALLOWED_HOSTS = [AWS_ELASTIC_IP, 'localhost', '127.0.0.1', '[::1]', ".%s" % SHORTURL_HOST, SHORTURL_HOST]

SHORTENING_POSTBACK = "your-shortening-postback-url-here"
ADMIN_POSTBACK = "your-Django-admin-postback-url-here"
JET_POSTBACK = "jet"
JET_DASHBOARD_POSTBACK = "jet/dashboard"

# If the SHORTURL_HOST or SECURE_SHORTURL_HOST value is entered into a browser with no path, it will redirect to this page
INDEX_HTML = "http://www.linkedin.com/in/bretlowery" # for example
STATIC_URL = '/static/'

# (Try to) prevent short URLs from containing profanity
# It's nowhere near perfect and there's no guarantee, but at least it's something
# FAST does a quick quality score check
# DEEP does a deep blacklist check, BUT it adds 2-10x to the time needed to create a short URL
# Note this is ONLY done once at short URL generation, NOT at actual subsequent short URL lookup and redirection time
#
ENABLE_FAST_PROFANITY_CHECKING = False
ENABLE_DEEP_PROFANITY_CHECKING = False
#
# If enabled, the following setting prevents the user from creating a short URL for any target (long) URL
# that contains profane language: JUST the URL; it does NOT check the target's content AT the URL. Note that this check
# is ONLY done once at short URL generation, NOT at actual subsequent short URL lookup and redirection time, so if the
# target changes and profanity is added, we won't catch it.
#
# The same Fast and/or Deep checks will be made as the short URL, depending on the settings above.
#
ENABLE_LONG_URL_PROFANITY_CHECKING = False

# Postgres DB
if DATABASE_MODE == 'dev':
    DATABASES = {
        'default': {
            'ENGINE':   'django.db.backends.postgresql_psycopg2',
            'NAME':     'your-db-name-here',
            'HOST':     'localhost',
            'USER':     'your-username-here',
            'PASSWORD': 'your-password-here',
            'PORT':      65432,
        }
    }
elif DATABASE_MODE == 'prod':
    DATABASES = {
        'default': {
            'ENGINE':   'django.db.backends.postgresql_psycopg2',
            'NAME':     'your-db-name-here',
            'HOST':     'your-aws-instance-name-here',
            'USER':     'your-username-here',
            'PASSWORD': 'your-password-here',
            'PORT':      5432,
        }
    }

# SECURITY WARNING: keep the secret key used in production secret!
SECRET_KEY = 'your-Django-secret-key-here'

CACHES = {
    'default': {
        'BACKEND': 'django.core.cache.backends.memcached.MemcachedCache',
        'LOCATION': '127.0.0.1:11211',
    }
}

# Internationalization
# https://docs.djangoproject.com/en/2.1/topics/i18n/

LANGUAGE_CODE = 'en-us'
TIME_ZONE = 'UTC'
USE_I18N = False
USE_L10N = True
USE_TZ = True

# geolocation lookups
GEOLOCATION_API_URL = "http://api.ipstack.com/%ip%?access_key=your-ipstack-api-key-value-here"

# Number of alphabetic characters in the short URL path (min 6, max 12)
SHORTURL_PATH_SIZE = 6

# Character set to use for the short URL path. Remove easily-confused characters "0", "O", "o", "1", and "l". Keep "L".
SHORTURL_PATH_ALPHABET = string.digits + string.ascii_letters
SHORTURL_PATH_ALPHABET = SHORTURL_PATH_ALPHABET.replace("0", "").replace("O", "").replace("o", "").replace("1", "").replace("l", "")

# If True, enable capture of the target long url's OpenGraph title ("og:title") and return it in the JSON along with the short url
# See: http://ogp.me
# For the Python PyOpenGraph site: https://pypi.python.org/pypi/PyOpenGraph
OGTITLE = True
RETURN_ALL_META = DEBUG

#
# Logging messages
#
# Enable/disable HTTP 302, 400, 404 error logging
LOG_HTTP200 = True
LOG_HTTP301 = True
LOG_HTTP302 = True
LOG_HTTP400 = True
LOG_HTTP403 = True
LOG_HTTP404 = True
LOG_PATH = '/var/logs'

# sorted in rough order of probability of occurrence for lookup performance
CANONICAL_MESSAGES = {
        'REQUEST_INVALID':              _('ERROR, a valid HTTP request was not received.'),
        'IP_LOOKUP_INVALID':            _('ERROR, could not resolve IP, {%s}'),
        'BLACKLISTED':                  _('403 Permission Denied (Blacklisted)'),
        'ROBOT':                        _('403 Permission Denied (Bot)'),
        'HTTP_301':                     _('301 Permanently redirecting to {%s}'),
        'HTTP_302':                     _('302 Redirecting to {%s}'),
        'HTTP_404':                     _('404 URL {%s} not found'),
        'LONG_URL_SUBMITTED':           _('200 Long URL {%s} submitted'),
        'VANITY_PATH_EXISTS':           _('ERROR, the proposed vanity path for the new short URL is already in use.'),
        'VANITY_PATH_INVALID':          _("'%s' is an invalid vanity URL. "
                                          "If provided, a vanity URL must be at least %d characters long and contain one or more "
                                          "letters, digits, hyphens, and/or underscores. No other characters are allowed; "
                                          "do not add slashes."),
        'SHORT_URL_ENCODING_MISMATCH':  _('ERROR, the short URL sent to this service is encoded differently from the original short URL '
                                          'provided and may pose a security risk. DO NOT USE the altered version.'),
        'SHORT_URL_INVALID':            _('ERROR, the constructed short URL {%s} is not a valid URL. '
                                          'If you supplied a custom short URL fragment, it may contain invalid characters.'),
        'SHORT_PATH_INVALID':           _('ERROR, the constructed short URL {%s} uses a reserved path%pl. '
                                          'If you supplied a custom short URL fragment, please use a different one.'),
        'SHORT_URL_NOT_FOUND':          _('ERROR, URL {%s} is not recognized by this service.'),
        'SHORT_URL_MISMATCH':           _('ERROR, the short URL sent to this service is different from the original short URL '
                                          'provided and may pose a security risk. DO NOT USE the altered version.'),
        'LONG_URL_MISSING':             _('ERROR, no long URL was submitted to the service.'),
        'LONG_URL_INVALID':             _('ERROR, the URL {%s} submitted for shortening is invalid%pl.'),
        'LONG_URL_CONTENT_MISSING':     _('ERROR, the content at the URL {%s} submitted for shortening does not exist or is not accessible by this service.'),
        'LONG_URL_CONTENT_INVALID':     _('ERROR, the content at the URL {%s} submitted for shortening is invalid%pl.'),
        'LONG_URL_RESUBMITTED':         _('200 Long URL {%s} resubmitted. Please reuse the existing short URL for this long URL.'),
        'MALFORMED_REQUEST':            _('ERROR, I don''t understand this request.'),
        'STARTUP':                      _('Snakr starting'),
        'PYTHON_VERSION':               _('Python version %s'),
        'DJANGO_VERSION':               _('Django version %s'),
        'LOADING_BLACKLIST':            _('Loading blacklist'),
        'LOADING_BOTLIST':              _('Loading known botlist'),
        'READY':                        _('Snakr is ready and listening'),
        'SHUTDOWN':                     _('Snakr stopping'),
        'HASH_COLLISION':               _('WARNING, hash collision detected on URL {%s}.'),
        'RECAPTCHA_LOW_SCORE':          _('Sorry, we are unable to service your request at this time.'),
        'RECAPTCHA_EXCEPTION':          _('Sorry, we are unable to service your request at this time.'),
        'RECAPTCHA_EXPIRED':            _('Sorry, your session has expired, please refresh the page and try again.'),
        'DISALLOW_DOUBLE_SHORTENING':   _('ERROR, looks like the long URL you are submitting may be a short URL generated by Snakr. '
                                          'Use the existing short URL or a different long URL.'),
        'BYLINE_INVALID':               _('ERROR, the byline provided contains language flagged as inappropriate.'),
        'DESCRIPTION_INVALID':          _('ERROR, a custom description, if provided, must be at least 100 characters long.'),

}

MESSAGE_OF_LAST_RESORT = 'ERROR, an unknown exception occurred'
LANGUAGE_ADDENDUM = _(' or contains language flagged as inappropriate')

USER_AGENT = "SnakrAWS/1.0 (URL Shortening and Analytics Service) (http://www.github.com/bretlowery) " \
             "(if u can read this, someone resolved a URL to you using me)"

BOTWHITELIST = ['LinkedInBot/1.0 (compatible; Mozilla/5.0; Apache-HttpClient +http://www.linkedin.com)', ]

BOTBLACKLIST = ['1job', 'abot', 'agentname', 'apachebench', 'aport', 'applesyndication', 'ask jeeves', 'ask+jeeves',
        'atomz', 'avantgo', 'baiduspider', 'blitzbot', 'bloglines', 'bordermanager', 'changedetection',
        'check_http', 'checkurl', 'chkd', 'contype', 'cosmos', 'download ninja', 'download+ninja', 'dts agent',
        'dts+agent', 'favorg', 'flashget', 'frontier', 'getright', 'golem', 'gomezagent', 'grabber',
        'hitlist', 'ia_archive', 'ibot', 'ichiro', 'ieautodiscovery', 'indy library', 'indy+library', 'infolink',
                'internet ninja', 'internet+ninja', 'internetseer', 'isilo', 'jakarta', 'jobo', 'justview', 'keynote', 'kinja',
                'larbin', 'libwww-perl', 'linkbot', 'linkchecker', 'linklint', 'linkscan', 'linkwalker', 'lisa', 'lwp', 'lydia',
                'magus bot', 'magus+bot', 'mediapartners-google', 'mfc_tear_sample',
                'microsoft scheduled cache content download service', 'microsoft url control',
                'microsoft+scheduled+cache+content+download+service', 'microsoft+url+control', 'miva', 'mj12bot', 'monitor',
                'monster', 'mozilla/5.0 (compatible; msie 5.0)', 'mozilla/5.0+(compatible;+msie+5.0)', 'ms frontpage',
                'ms search', 'ms+frontpage', 'ms+search', 'msnptc', 'nbot', 'newsnow', 'nextgensearchbot', 'nomad', 'npbot',
                'nutch', 'nutscrape', 'omniexplorer', 'patric', 'pioneer', 'pluck', 'plumtree', 'powermarks', 'psbot', 'rpt-http',
                'rssreader', 'scooter', 'seekbot', 'sherlock', 'shopwiki', 'slurp', 'stackrambler', 'sucker', 'templeton', '/teoma',
                'thunderstone', 't-h-u-n-d-e-r-s-t-o-n-e', 'topix', 'ukonline', 'ultraseek', 'urchin', 'vagabondo', 'voyager',
                'web downloader', 'web+downloader', 'webauto', 'webcapture', 'webcheck', 'webcopier', 'webdup', 'webtool', 'wfarc',
                'wget', 'whatsup', 'xenu', 'yacy', 'zealbot', 'zeus', 'ez publish link validator', 'ez+publish+link+validator',
                'terrawizbot', 'goldfire', 'sitevigil', 'iopus', 'microsoft bits', 'microsoft+bits', 'heritrix', 'yahoofeedseeker',
                'internal zero-knowledge agent', 'internal+zero-knowledge+agent', 'surveybot/', 'liferea', 'yahooseeker', 'findlinks',
                'oodlebot', 'adsbot-google', 'innovantagebot', 'khte', 'ktxn', 'advanced email extractor', 'advanced+email+extractor',
                'moreoverbot', 'webbot', 'search_comments\\at\\sensis\\dot\\com\\dot\\au', 'panscient.com', 'snoopy', 'bot/1.0',
                'universalsearch', 'maxamine', 'argus', 'google wireless transcoder', 'google+wireless+transcoder', 'clickajob',
                'jobrapido', 'python-urllib', 'isearch', 'http://bot.ims.ca', 'system center operations manager',
                'system+center+operations+manager', 'joedog', 'websitepulse', 'bitvouseragent',
                'mozilla/4.0 (compatible; msie 6.0; windows nt 5.1;1813)',
                'mozilla/4.0+(compatible;+msie+6.0;+windows+nt+5.1;1813)',
                'paros', 'watchmouse', 'proximic', 'scoutjet', 'twiceler', 'pingdom', 'europarchive', 'search-engine-studio',
                'webmetrics', 'holmes', 'alertsite', 'yahoo pipes', 'yahoo+pipes', 'simplepie', 'drupal', 'htmlparser',
                'watchfire webxm', 'watchfire+webxm', 'snappreviewbot', 'snapbot', 'daumoa', 'nielsen adr', 'nielsen+adr',
                'evrinid', 'fdm 3.x', 'fdm+3.x', 'isense bot', 'isense+bot', 'trovit', 'riverglassscanner', 'wepbot', 'mlbot',
                'siteimprove', 'archive.org', 'vocusbot', 'fairshare', 'blp_bbot', 'w3c_validator',
                '(simulated_by_webserver_stress_tool)', 'wapt', 'updatepatrol', 'sitecon', 'twitterbot', 'bingbot', 'www-mechanize',
                'google web preview', 'google+web+preview', 'adgbot', 'httpunit', 'curious george', 'curious+george', 'postrank',
                'httpcomponents', 'twisted pagegetter', 'twisted+pagegetter', 'servers alive url check', 'servers+alive+url+check',
                'appengine-google', 'yioopbot', 'flamingo_searchengine', 'atomic_email_hunter', 'feedburner', 'talktalk',
                'facebookexternalhit', 'adbeat', 'sjn', 'outbrain', 'tweetmemebot', 'wasalive', 'wikiwix-bot', 'ezooms', 'hiscan',
                'd24y-aegis', 'google-hoteladsverifier', 'fupbot', 'moatbot', 'vmcbot', 'wusage/', 'wikiofeedbot', 'jobblebot',
                'companydatatree', 'cookiereports', 'wbsearchbot', 'bingpreview', 'scan', 'smokeping', 'flamingosearch', 'reconnoiter',
                'ec2linkfinder', 'citeseerxbot', 'funnelback', 'feed43', 'auditbot', 'genieo', 'nerdbynature', 'python-httplib',
                'cutbot', 'server density external llama', 'server+density+external+llama', 'mna digital circonus check',
                'mna+digital+circonus+check', 'aware', 'appneta sequencer', 'appneta+sequencer', 'scanalert', 'catchpoint',
                'discoverybot', 'jooblebot', 'bitlybot', 'adr)', 'yottaamonitor', 'adometrybot', 'tsmbot', 'orangebot-mobile',
                'phantomjs', 'scc internet services - url check', 'scc+internet+services+-+url+check',
                'apache-httpclient/4.1.1 (java 1.5)', 'apache-httpclient/4.1.1+(java+1.5)', 'tagscanner', 'loadimpactpageanalyzer',
                'cfschedule', 'searchme.com/support/', 'b2w', 'coast', 'combine', 'crawl', 'crescent', 'curl', 'dialer', 'echo',
                'fetch', 'grub', 'harvest', 'httrack', 'newsapp', 'ng/2.0', 'obot', 'pita', 'sohu', 'spider', 'spike', 'stuff',
                'teleport', 'webtrends', 'worm', 'yandex', 'freedom',
                'livelapbot', 'help@dataminr.com', 'everyonesocialbot', 'tweetedtimes.com', 'metauri api']

RESERVED_PATHS = [
    _('home'),
    _('static'),
    _('media'),
    _('theme'),
    _('robot'),
    _('ads'),
    _('image'),
    _('account'),
    _('login'),
    _('logout'),
    _('profile'),
    _('admin'),
    _('last'),
    'localhost',
    'api',
    SHORTENING_POSTBACK,
    ADMIN_POSTBACK,
    JET_POSTBACK,
    JET_DASHBOARD_POSTBACK
    ]
